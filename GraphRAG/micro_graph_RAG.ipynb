{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import re \n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "import dotenv\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "# from project import web_crawl\n",
    "import subprocess\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of top Tech leaders\n",
    "url_list=[  \n",
    "    'https://en.wikipedia.org/wiki/Elon_Musk',\n",
    "    'https://en.wikipedia.org/wiki/Mark_Zuckerberg',\n",
    "    'https://en.wikipedia.org/wiki/Bill_Gates',\n",
    "    'https://en.wikipedia.org/wiki/Jeff_Bezos',\n",
    "    'https://en.wikipedia.org/wiki/Steve_Jobs',\n",
    "    'https://en.wikipedia.org/wiki/Sam_Altman',\n",
    "    'https://en.wikipedia.org/wiki/Larry_Ellison',\n",
    "    'https://en.wikipedia.org/wiki/Larry_Page',\n",
    "    'https://en.wikipedia.org/wiki/Sundar_Pichai',\n",
    "    'https://en.wikipedia.org/wiki/Satya_Nadella' \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to clean the extracted web URL data\n",
    "import re #for regular expression \n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]*?>', '', text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "    # Trim leading and trailing whitespace\n",
    "    text = text.strip()\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the data from the URLs\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "\n",
    "def extract_data_from_URL(url):\n",
    "    loader=WebBaseLoader([url])\n",
    "    data=loader.load().pop().page_content\n",
    "    data=clean_text(data)\n",
    "    documents=[Document(page_content=data)]\n",
    "    # print(documents)\n",
    "    splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=100)\n",
    "    smaller_doc=splitter.split_documents(documents)\n",
    "    #print(len(smaller_doc))\n",
    "    return smaller_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv \n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from openai import AzureOpenAI\n",
    "import os  \n",
    "\n",
    "dotenv.load_dotenv()\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_version=os.getenv(\"AZURE_OpenAI_API_VERSION_3\"),\n",
    "    azure_deployment=os.getenv('AZURE_OPENAI_DEPLOYMENT_MODEL_3'),\n",
    "    model_name=os.getenv('AZURE_OPENAI_DEPLOYMENT_MODEL_3'),\n",
    "    api_key=os.getenv('OPENAI_API_KEY_3'),\n",
    "    azure_endpoint=os.getenv('AZURE_OpenAI_ENDPOINT_3')\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in url_list:\n",
    "    with open(f'../input/{url.split(\"/\")[-1]}.txt','w') as file:\n",
    "        smaller_doc=extract_data_from_URL(url)\n",
    "        for doc in smaller_doc:\n",
    "            file.write(str(doc.page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error executing the command\n",
      "┌───────────────────── Traceback (most recent call last) ─────────────────────┐\n",
      "│ D:\\pythonProjects\\KAG_Testing\\graphragvenv\\lib\\site-packages\\graphrag\\cli\\m │\n",
      "│ ain.py:178 in _index_cli                                                    │\n",
      "│                                                                             │\n",
      "│   175 │   \"\"\"Build a knowledge graph index.\"\"\"                              │\n",
      "│   176 │   from graphrag.cli.index import index_cli                          │\n",
      "│   177 │                                                                     │\n",
      "│ > 178 │   index_cli(                                                        │\n",
      "│   179 │   │   root_dir=root,                                                │\n",
      "│   180 │   │   verbose=verbose,                                              │\n",
      "│   181 │   │   resume=resume,                                                │\n",
      "│                                                                             │\n",
      "│ ┌──────────────────────────────── locals ─────────────────────────────────┐ │\n",
      "│ │           cache = True                                                  │ │\n",
      "│ │          config = None                                                  │ │\n",
      "│ │         dry_run = False                                                 │ │\n",
      "│ │          logger = <LoggerType.RICH: 'rich'>                             │ │\n",
      "│ │      memprofile = False                                                 │ │\n",
      "│ │          output = None                                                  │ │\n",
      "│ │          resume = None                                                  │ │\n",
      "│ │            root = WindowsPath('D:/pythonProjects/KAG_Testing/GraphRAG') │ │\n",
      "│ │ skip_validation = False                                                 │ │\n",
      "│ │         verbose = False                                                 │ │\n",
      "│ └─────────────────────────────────────────────────────────────────────────┘ │\n",
      "│                                                                             │\n",
      "│ D:\\pythonProjects\\KAG_Testing\\graphragvenv\\lib\\site-packages\\graphrag\\cli\\i │\n",
      "│ ndex.py:81 in index_cli                                                     │\n",
      "│                                                                             │\n",
      "│    78 │   \"\"\"Run the pipeline with the given config.\"\"\"                     │\n",
      "│    79 │   config = load_config(root_dir, config_filepath)                   │\n",
      "│    80 │                                                                     │\n",
      "│ >  81 │   _run_index(                                                       │\n",
      "│    82 │   │   config=config,                                                │\n",
      "│    83 │   │   verbose=verbose,                                              │\n",
      "│    84 │   │   resume=resume,                                                │\n",
      "│                                                                             │\n",
      "│ ┌──────────────────────────────── locals ─────────────────────────────────┐ │\n",
      "│ │           cache = True                                                  │ │\n",
      "│ │          config = GraphRagConfig(                                       │ │\n",
      "│ │                   │   llm=LLMParameters(                                │ │\n",
      "│ │                   │   │                                                 │ │\n",
      "│ │                   api_key='FGH7P5rBJafjdYizJNC38PRxscCX8lYD5I5ddEZy2Gy… │ │\n",
      "│ │                   │   │   type=\"openai_chat\",                           │ │\n",
      "│ │                   │   │   encoding_model='cl100k_base',                 │ │\n",
      "│ │                   │   │   model='gpt-4-turbo-preview',                  │ │\n",
      "│ │                   │   │   max_tokens=4000,                              │ │\n",
      "│ │                   │   │   temperature=0.0,                              │ │\n",
      "│ │                   │   │   top_p=1.0,                                    │ │\n",
      "│ │                   │   │   n=1,                                          │ │\n",
      "│ │                   │   │   frequency_penalty=0.0,                        │ │\n",
      "│ │                   │   │   presence_penalty=0.0,                         │ │\n",
      "│ │                   │   │   request_timeout=180.0,                        │ │\n",
      "│ │                   │   │   api_base=None,                                │ │\n",
      "│ │                   │   │   api_version=None,                             │ │\n",
      "│ │                   │   │   organization=None,                            │ │\n",
      "│ │                   │   │   proxy=None,                                   │ │\n",
      "│ │                   │   │   audience=None,                                │ │\n",
      "│ │                   │   │   deployment_name=None,                         │ │\n",
      "│ │                   │   │   model_supports_json=None,                     │ │\n",
      "│ │                   │   │   tokens_per_minute=0,                          │ │\n",
      "│ │                   │   │   requests_per_minute=0,                        │ │\n",
      "│ │                   │   │   max_retries=10,                               │ │\n",
      "│ │                   │   │   max_retry_wait=10.0,                          │ │\n",
      "│ │                   │   │   sleep_on_rate_limit_recommendation=True,      │ │\n",
      "│ │                   │   │   concurrent_requests=25,                       │ │\n",
      "│ │                   │   │   responses=None                                │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   parallelization=ParallelizationParameters(        │ │\n",
      "│ │                   │   │   stagger=0.3,                                  │ │\n",
      "│ │                   │   │   num_threads=50                                │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   async_mode=<AsyncType.Threaded: 'threaded'>,      │ │\n",
      "│ │                   │                                                     │ │\n",
      "│ │                   root_dir='D:\\\\pythonProjects\\\\KAG_Testing\\\\GraphRAG', │ │\n",
      "│ │                   │   reporting=ReportingConfig(                        │ │\n",
      "│ │                   │   │   type=\"file\",                                  │ │\n",
      "│ │                   │   │                                                 │ │\n",
      "│ │                   base_dir='D:\\\\pythonProjects\\\\KAG_Testing\\\\GraphRAG\\… │ │\n",
      "│ │                   │   │   connection_string=None,                       │ │\n",
      "│ │                   │   │   container_name=None,                          │ │\n",
      "│ │                   │   │   storage_account_blob_url=None                 │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   storage=StorageConfig(                            │ │\n",
      "│ │                   │   │   type=\"file\",                                  │ │\n",
      "│ │                   │   │                                                 │ │\n",
      "│ │                   base_dir='D:\\\\pythonProjects\\\\KAG_Testing\\\\GraphRAG\\… │ │\n",
      "│ │                   │   │   connection_string=None,                       │ │\n",
      "│ │                   │   │   container_name=None,                          │ │\n",
      "│ │                   │   │   storage_account_blob_url=None,                │ │\n",
      "│ │                   │   │   cosmosdb_account_url=None                     │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   update_index_storage=None,                        │ │\n",
      "│ │                   │   cache=CacheConfig(                                │ │\n",
      "│ │                   │   │   type=\"file\",                                  │ │\n",
      "│ │                   │   │   base_dir='cache',                             │ │\n",
      "│ │                   │   │   connection_string=None,                       │ │\n",
      "│ │                   │   │   container_name=None,                          │ │\n",
      "│ │                   │   │   storage_account_blob_url=None,                │ │\n",
      "│ │                   │   │   cosmosdb_account_url=None                     │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   input=InputConfig(                                │ │\n",
      "│ │                   │   │   type=\"file\",                                  │ │\n",
      "│ │                   │   │   file_type=\"text\",                             │ │\n",
      "│ │                   │   │   base_dir='input',                             │ │\n",
      "│ │                   │   │   connection_string=None,                       │ │\n",
      "│ │                   │   │   storage_account_blob_url=None,                │ │\n",
      "│ │                   │   │   container_name=None,                          │ │\n",
      "│ │                   │   │   encoding='utf-8',                             │ │\n",
      "│ │                   │   │   file_pattern='.*\\\\.csv$',                     │ │\n",
      "│ │                   │   │   file_filter=None,                             │ │\n",
      "│ │                   │   │   source_column=None,                           │ │\n",
      "│ │                   │   │   timestamp_column=None,                        │ │\n",
      "│ │                   │   │   timestamp_format=None,                        │ │\n",
      "│ │                   │   │   text_column='text',                           │ │\n",
      "│ │                   │   │   title_column=None,                            │ │\n",
      "│ │                   │   │   document_attribute_columns=[]                 │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   embed_graph=EmbedGraphConfig(                     │ │\n",
      "│ │                   │   │   enabled=False,                                │ │\n",
      "│ │                   │   │   dimensions=1536,                              │ │\n",
      "│ │                   │   │   num_walks=10,                                 │ │\n",
      "│ │                   │   │   walk_length=40,                               │ │\n",
      "│ │                   │   │   window_size=2,                                │ │\n",
      "│ │                   │   │   iterations=3,                                 │ │\n",
      "│ │                   │   │   random_seed=597832,                           │ │\n",
      "│ │                   │   │   use_lcc=True                                  │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   embeddings=TextEmbeddingConfig(                   │ │\n",
      "│ │                   │   │   llm=LLMParameters(                            │ │\n",
      "│ │                   │   │   │                                             │ │\n",
      "│ │                   api_key='FGH7P5rBJafjdYizJNC38PRxscCX8lYD5I5ddEZy2Gy… │ │\n",
      "│ │                   │   │   │   type=\"openai_embedding\",                  │ │\n",
      "│ │                   │   │   │   encoding_model='cl100k_base',             │ │\n",
      "│ │                   │   │   │   model='text-embedding-3-small',           │ │\n",
      "│ │                   │   │   │   max_tokens=4000,                          │ │\n",
      "│ │                   │   │   │   temperature=0,                            │ │\n",
      "│ │                   │   │   │   top_p=1,                                  │ │\n",
      "│ │                   │   │   │   n=1,                                      │ │\n",
      "│ │                   │   │   │   frequency_penalty=0.0,                    │ │\n",
      "│ │                   │   │   │   presence_penalty=0.0,                     │ │\n",
      "│ │                   │   │   │   request_timeout=180.0,                    │ │\n",
      "│ │                   │   │   │   api_base=None,                            │ │\n",
      "│ │                   │   │   │   api_version=None,                         │ │\n",
      "│ │                   │   │   │   organization=None,                        │ │\n",
      "│ │                   │   │   │   proxy=None,                               │ │\n",
      "│ │                   │   │   │   audience=None,                            │ │\n",
      "│ │                   │   │   │   deployment_name=None,                     │ │\n",
      "│ │                   │   │   │   model_supports_json=None,                 │ │\n",
      "│ │                   │   │   │   tokens_per_minute=0,                      │ │\n",
      "│ │                   │   │   │   requests_per_minute=0,                    │ │\n",
      "│ │                   │   │   │   max_retries=10,                           │ │\n",
      "│ │                   │   │   │   max_retry_wait=10.0,                      │ │\n",
      "│ │                   │   │   │   sleep_on_rate_limit_recommendation=True,  │ │\n",
      "│ │                   │   │   │   concurrent_requests=25,                   │ │\n",
      "│ │                   │   │   │   responses=None                            │ │\n",
      "│ │                   │   │   ),                                            │ │\n",
      "│ │                   │   │   parallelization=ParallelizationParameters(    │ │\n",
      "│ │                   │   │   │   stagger=0.3,                              │ │\n",
      "│ │                   │   │   │   num_threads=50                            │ │\n",
      "│ │                   │   │   ),                                            │ │\n",
      "│ │                   │   │   async_mode=<AsyncType.Threaded: 'threaded'>,  │ │\n",
      "│ │                   │   │   batch_size=16,                                │ │\n",
      "│ │                   │   │   batch_max_tokens=8191,                        │ │\n",
      "│ │                   │   │   target=\"required\",                            │ │\n",
      "│ │                   │   │   skip=[],                                      │ │\n",
      "│ │                   │   │   vector_store=None,                            │ │\n",
      "│ │                   │   │   strategy=None                                 │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   chunks=ChunkingConfig(                            │ │\n",
      "│ │                   │   │   size=1200,                                    │ │\n",
      "│ │                   │   │   overlap=100,                                  │ │\n",
      "│ │                   │   │   group_by_columns=['id'],                      │ │\n",
      "│ │                   │   │   strategy=\"tokens\",                            │ │\n",
      "│ │                   │   │   encoding_model='cl100k_base'                  │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   snapshots=SnapshotsConfig(                        │ │\n",
      "│ │                   │   │   embeddings=False,                             │ │\n",
      "│ │                   │   │   graphml=False,                                │ │\n",
      "│ │                   │   │   transient=False                               │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   entity_extraction=EntityExtractionConfig(         │ │\n",
      "│ │                   │   │   llm=LLMParameters(                            │ │\n",
      "│ │                   │   │   │                                             │ │\n",
      "│ │                   api_key='FGH7P5rBJafjdYizJNC38PRxscCX8lYD5I5ddEZy2Gy… │ │\n",
      "│ │                   │   │   │   type=\"openai_chat\",                       │ │\n",
      "│ │                   │   │   │   encoding_model='cl100k_base',             │ │\n",
      "│ │                   │   │   │   model='gpt-4-turbo-preview',              │ │\n",
      "│ │                   │   │   │   max_tokens=4000,                          │ │\n",
      "│ │                   │   │   │   temperature=0.0,                          │ │\n",
      "│ │                   │   │   │   top_p=1.0,                                │ │\n",
      "│ │                   │   │   │   n=1,                                      │ │\n",
      "│ │                   │   │   │   frequency_penalty=0.0,                    │ │\n",
      "│ │                   │   │   │   presence_penalty=0.0,                     │ │\n",
      "│ │                   │   │   │   request_timeout=180.0,                    │ │\n",
      "│ │                   │   │   │   api_base=None,                            │ │\n",
      "│ │                   │   │   │   api_version=None,                         │ │\n",
      "│ │                   │   │   │   organization=None,                        │ │\n",
      "│ │                   │   │   │   proxy=None,                               │ │\n",
      "│ │                   │   │   │   audience=None,                            │ │\n",
      "│ │                   │   │   │   deployment_name=None,                     │ │\n",
      "│ │                   │   │   │   model_supports_json=None,                 │ │\n",
      "│ │                   │   │   │   tokens_per_minute=0,                      │ │\n",
      "│ │                   │   │   │   requests_per_minute=0,                    │ │\n",
      "│ │                   │   │   │   max_retries=10,                           │ │\n",
      "│ │                   │   │   │   max_retry_wait=10.0,                      │ │\n",
      "│ │                   │   │   │   sleep_on_rate_limit_recommendation=True,  │ │\n",
      "│ │                   │   │   │   concurrent_requests=25,                   │ │\n",
      "│ │                   │   │   │   responses=None                            │ │\n",
      "│ │                   │   │   ),                                            │ │\n",
      "│ │                   │   │   parallelization=ParallelizationParameters(    │ │\n",
      "│ │                   │   │   │   stagger=0.3,                              │ │\n",
      "│ │                   │   │   │   num_threads=50                            │ │\n",
      "│ │                   │   │   ),                                            │ │\n",
      "│ │                   │   │   async_mode=<AsyncType.Threaded: 'threaded'>,  │ │\n",
      "│ │                   │   │   prompt=None,                                  │ │\n",
      "│ │                   │   │   entity_types=[                                │ │\n",
      "│ │                   │   │   │   'organization',                           │ │\n",
      "│ │                   │   │   │   'person',                                 │ │\n",
      "│ │                   │   │   │   'geo',                                    │ │\n",
      "│ │                   │   │   │   'event'                                   │ │\n",
      "│ │                   │   │   ],                                            │ │\n",
      "│ │                   │   │   max_gleanings=1,                              │ │\n",
      "│ │                   │   │   strategy=None,                                │ │\n",
      "│ │                   │   │   encoding_model='cl100k_base'                  │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │                                                     │ │\n",
      "│ │                   summarize_descriptions=SummarizeDescriptionsConfig(   │ │\n",
      "│ │                   │   │   llm=LLMParameters(                            │ │\n",
      "│ │                   │   │   │                                             │ │\n",
      "│ │                   api_key='FGH7P5rBJafjdYizJNC38PRxscCX8lYD5I5ddEZy2Gy… │ │\n",
      "│ │                   │   │   │   type=\"openai_chat\",                       │ │\n",
      "│ │                   │   │   │   encoding_model='cl100k_base',             │ │\n",
      "│ │                   │   │   │   model='gpt-4-turbo-preview',              │ │\n",
      "│ │                   │   │   │   max_tokens=4000,                          │ │\n",
      "│ │                   │   │   │   temperature=0.0,                          │ │\n",
      "│ │                   │   │   │   top_p=1.0,                                │ │\n",
      "│ │                   │   │   │   n=1,                                      │ │\n",
      "│ │                   │   │   │   frequency_penalty=0.0,                    │ │\n",
      "│ │                   │   │   │   presence_penalty=0.0,                     │ │\n",
      "│ │                   │   │   │   request_timeout=180.0,                    │ │\n",
      "│ │                   │   │   │   api_base=None,                            │ │\n",
      "│ │                   │   │   │   api_version=None,                         │ │\n",
      "│ │                   │   │   │   organization=None,                        │ │\n",
      "│ │                   │   │   │   proxy=None,                               │ │\n",
      "│ │                   │   │   │   audience=None,                            │ │\n",
      "│ │                   │   │   │   deployment_name=None,                     │ │\n",
      "│ │                   │   │   │   model_supports_json=None,                 │ │\n",
      "│ │                   │   │   │   tokens_per_minute=0,                      │ │\n",
      "│ │                   │   │   │   requests_per_minute=0,                    │ │\n",
      "│ │                   │   │   │   max_retries=10,                           │ │\n",
      "│ │                   │   │   │   max_retry_wait=10.0,                      │ │\n",
      "│ │                   │   │   │   sleep_on_rate_limit_recommendation=True,  │ │\n",
      "│ │                   │   │   │   concurrent_requests=25,                   │ │\n",
      "│ │                   │   │   │   responses=None                            │ │\n",
      "│ │                   │   │   ),                                            │ │\n",
      "│ │                   │   │   parallelization=ParallelizationParameters(    │ │\n",
      "│ │                   │   │   │   stagger=0.3,                              │ │\n",
      "│ │                   │   │   │   num_threads=50                            │ │\n",
      "│ │                   │   │   ),                                            │ │\n",
      "│ │                   │   │   async_mode=<AsyncType.Threaded: 'threaded'>,  │ │\n",
      "│ │                   │   │   prompt=None,                                  │ │\n",
      "│ │                   │   │   max_length=500,                               │ │\n",
      "│ │                   │   │   strategy=None                                 │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   community_reports=CommunityReportsConfig(         │ │\n",
      "│ │                   │   │   llm=LLMParameters(                            │ │\n",
      "│ │                   │   │   │                                             │ │\n",
      "│ │                   api_key='FGH7P5rBJafjdYizJNC38PRxscCX8lYD5I5ddEZy2Gy… │ │\n",
      "│ │                   │   │   │   type=\"openai_chat\",                       │ │\n",
      "│ │                   │   │   │   encoding_model='cl100k_base',             │ │\n",
      "│ │                   │   │   │   model='gpt-4-turbo-preview',              │ │\n",
      "│ │                   │   │   │   max_tokens=4000,                          │ │\n",
      "│ │                   │   │   │   temperature=0.0,                          │ │\n",
      "│ │                   │   │   │   top_p=1.0,                                │ │\n",
      "│ │                   │   │   │   n=1,                                      │ │\n",
      "│ │                   │   │   │   frequency_penalty=0.0,                    │ │\n",
      "│ │                   │   │   │   presence_penalty=0.0,                     │ │\n",
      "│ │                   │   │   │   request_timeout=180.0,                    │ │\n",
      "│ │                   │   │   │   api_base=None,                            │ │\n",
      "│ │                   │   │   │   api_version=None,                         │ │\n",
      "│ │                   │   │   │   organization=None,                        │ │\n",
      "│ │                   │   │   │   proxy=None,                               │ │\n",
      "│ │                   │   │   │   audience=None,                            │ │\n",
      "│ │                   │   │   │   deployment_name=None,                     │ │\n",
      "│ │                   │   │   │   model_supports_json=None,                 │ │\n",
      "│ │                   │   │   │   tokens_per_minute=0,                      │ │\n",
      "│ │                   │   │   │   requests_per_minute=0,                    │ │\n",
      "│ │                   │   │   │   max_retries=10,                           │ │\n",
      "│ │                   │   │   │   max_retry_wait=10.0,                      │ │\n",
      "│ │                   │   │   │   sleep_on_rate_limit_recommendation=True,  │ │\n",
      "│ │                   │   │   │   concurrent_requests=25,                   │ │\n",
      "│ │                   │   │   │   responses=None                            │ │\n",
      "│ │                   │   │   ),                                            │ │\n",
      "│ │                   │   │   parallelization=ParallelizationParameters(    │ │\n",
      "│ │                   │   │   │   stagger=0.3,                              │ │\n",
      "│ │                   │   │   │   num_threads=50                            │ │\n",
      "│ │                   │   │   ),                                            │ │\n",
      "│ │                   │   │   async_mode=<AsyncType.Threaded: 'threaded'>,  │ │\n",
      "│ │                   │   │   prompt=None,                                  │ │\n",
      "│ │                   │   │   max_length=2000,                              │ │\n",
      "│ │                   │   │   max_input_length=8000,                        │ │\n",
      "│ │                   │   │   strategy=None                                 │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   claim_extraction=ClaimExtractionConfig(           │ │\n",
      "│ │                   │   │   llm=LLMParameters(                            │ │\n",
      "│ │                   │   │   │                                             │ │\n",
      "│ │                   api_key='FGH7P5rBJafjdYizJNC38PRxscCX8lYD5I5ddEZy2Gy… │ │\n",
      "│ │                   │   │   │   type=\"openai_chat\",                       │ │\n",
      "│ │                   │   │   │   encoding_model='cl100k_base',             │ │\n",
      "│ │                   │   │   │   model='gpt-4-turbo-preview',              │ │\n",
      "│ │                   │   │   │   max_tokens=4000,                          │ │\n",
      "│ │                   │   │   │   temperature=0.0,                          │ │\n",
      "│ │                   │   │   │   top_p=1.0,                                │ │\n",
      "│ │                   │   │   │   n=1,                                      │ │\n",
      "│ │                   │   │   │   frequency_penalty=0.0,                    │ │\n",
      "│ │                   │   │   │   presence_penalty=0.0,                     │ │\n",
      "│ │                   │   │   │   request_timeout=180.0,                    │ │\n",
      "│ │                   │   │   │   api_base=None,                            │ │\n",
      "│ │                   │   │   │   api_version=None,                         │ │\n",
      "│ │                   │   │   │   organization=None,                        │ │\n",
      "│ │                   │   │   │   proxy=None,                               │ │\n",
      "│ │                   │   │   │   audience=None,                            │ │\n",
      "│ │                   │   │   │   deployment_name=None,                     │ │\n",
      "│ │                   │   │   │   model_supports_json=None,                 │ │\n",
      "│ │                   │   │   │   tokens_per_minute=0,                      │ │\n",
      "│ │                   │   │   │   requests_per_minute=0,                    │ │\n",
      "│ │                   │   │   │   max_retries=10,                           │ │\n",
      "│ │                   │   │   │   max_retry_wait=10.0,                      │ │\n",
      "│ │                   │   │   │   sleep_on_rate_limit_recommendation=True,  │ │\n",
      "│ │                   │   │   │   concurrent_requests=25,                   │ │\n",
      "│ │                   │   │   │   responses=None                            │ │\n",
      "│ │                   │   │   ),                                            │ │\n",
      "│ │                   │   │   parallelization=ParallelizationParameters(    │ │\n",
      "│ │                   │   │   │   stagger=0.3,                              │ │\n",
      "│ │                   │   │   │   num_threads=50                            │ │\n",
      "│ │                   │   │   ),                                            │ │\n",
      "│ │                   │   │   async_mode=<AsyncType.Threaded: 'threaded'>,  │ │\n",
      "│ │                   │   │   enabled=False,                                │ │\n",
      "│ │                   │   │   prompt=None,                                  │ │\n",
      "│ │                   │   │   description='Any claims or facts that could   │ │\n",
      "│ │                   be relevant to information discovery.',               │ │\n",
      "│ │                   │   │   max_gleanings=1,                              │ │\n",
      "│ │                   │   │   strategy=None,                                │ │\n",
      "│ │                   │   │   encoding_model='cl100k_base'                  │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   cluster_graph=ClusterGraphConfig(                 │ │\n",
      "│ │                   │   │   max_cluster_size=10,                          │ │\n",
      "│ │                   │   │   use_lcc=True,                                 │ │\n",
      "│ │                   │   │   seed=3735928559                               │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   umap=UmapConfig(enabled=False),                   │ │\n",
      "│ │                   │   local_search=LocalSearchConfig(                   │ │\n",
      "│ │                   │   │   prompt=None,                                  │ │\n",
      "│ │                   │   │   text_unit_prop=0.5,                           │ │\n",
      "│ │                   │   │   community_prop=0.15,                          │ │\n",
      "│ │                   │   │   conversation_history_max_turns=5,             │ │\n",
      "│ │                   │   │   top_k_entities=10,                            │ │\n",
      "│ │                   │   │   top_k_relationships=10,                       │ │\n",
      "│ │                   │   │   temperature=0.0,                              │ │\n",
      "│ │                   │   │   top_p=1.0,                                    │ │\n",
      "│ │                   │   │   n=1,                                          │ │\n",
      "│ │                   │   │   max_tokens=12000,                             │ │\n",
      "│ │                   │   │   llm_max_tokens=2000                           │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   global_search=GlobalSearchConfig(                 │ │\n",
      "│ │                   │   │   map_prompt=None,                              │ │\n",
      "│ │                   │   │   reduce_prompt=None,                           │ │\n",
      "│ │                   │   │   knowledge_prompt=None,                        │ │\n",
      "│ │                   │   │   temperature=0.0,                              │ │\n",
      "│ │                   │   │   top_p=1.0,                                    │ │\n",
      "│ │                   │   │   n=1,                                          │ │\n",
      "│ │                   │   │   max_tokens=12000,                             │ │\n",
      "│ │                   │   │   data_max_tokens=12000,                        │ │\n",
      "│ │                   │   │   map_max_tokens=1000,                          │ │\n",
      "│ │                   │   │   reduce_max_tokens=2000,                       │ │\n",
      "│ │                   │   │   concurrency=32,                               │ │\n",
      "│ │                   │   │   dynamic_search_llm='gpt-4o-mini',             │ │\n",
      "│ │                   │   │   dynamic_search_threshold=1,                   │ │\n",
      "│ │                   │   │   dynamic_search_keep_parent=False,             │ │\n",
      "│ │                   │   │   dynamic_search_num_repeats=1,                 │ │\n",
      "│ │                   │   │   dynamic_search_use_summary=False,             │ │\n",
      "│ │                   │   │   dynamic_search_concurrent_coroutines=16,      │ │\n",
      "│ │                   │   │   dynamic_search_max_level=2                    │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   drift_search=DRIFTSearchConfig(                   │ │\n",
      "│ │                   │   │   prompt=None,                                  │ │\n",
      "│ │                   │   │   temperature=0.0,                              │ │\n",
      "│ │                   │   │   top_p=1.0,                                    │ │\n",
      "│ │                   │   │   n=3,                                          │ │\n",
      "│ │                   │   │   max_tokens=12000,                             │ │\n",
      "│ │                   │   │   data_max_tokens=12000,                        │ │\n",
      "│ │                   │   │   concurrency=32,                               │ │\n",
      "│ │                   │   │   drift_k_followups=20,                         │ │\n",
      "│ │                   │   │   primer_folds=5,                               │ │\n",
      "│ │                   │   │   primer_llm_max_tokens=12000,                  │ │\n",
      "│ │                   │   │   n_depth=3,                                    │ │\n",
      "│ │                   │   │   local_search_text_unit_prop=0.9,              │ │\n",
      "│ │                   │   │   local_search_community_prop=0.1,              │ │\n",
      "│ │                   │   │   local_search_top_k_mapped_entities=10,        │ │\n",
      "│ │                   │   │   local_search_top_k_relationships=10,          │ │\n",
      "│ │                   │   │   local_search_max_data_tokens=12000,           │ │\n",
      "│ │                   │   │   local_search_temperature=0.0,                 │ │\n",
      "│ │                   │   │   local_search_top_p=1.0,                       │ │\n",
      "│ │                   │   │   local_search_n=1,                             │ │\n",
      "│ │                   │   │   local_search_llm_max_gen_tokens=2000          │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   basic_search=BasicSearchConfig(                   │ │\n",
      "│ │                   │   │   prompt=None,                                  │ │\n",
      "│ │                   │   │   text_unit_prop=0.5,                           │ │\n",
      "│ │                   │   │   conversation_history_max_turns=5,             │ │\n",
      "│ │                   │   │   temperature=0.0,                              │ │\n",
      "│ │                   │   │   top_p=1.0,                                    │ │\n",
      "│ │                   │   │   n=1,                                          │ │\n",
      "│ │                   │   │   max_tokens=12000,                             │ │\n",
      "│ │                   │   │   llm_max_tokens=2000                           │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   encoding_model='cl100k_base',                     │ │\n",
      "│ │                   │   skip_workflows=[]                                 │ │\n",
      "│ │                   )                                                     │ │\n",
      "│ │ config_filepath = None                                                  │ │\n",
      "│ │         dry_run = False                                                 │ │\n",
      "│ │          logger = <LoggerType.RICH: 'rich'>                             │ │\n",
      "│ │      memprofile = False                                                 │ │\n",
      "│ │      output_dir = None                                                  │ │\n",
      "│ │          resume = None                                                  │ │\n",
      "│ │        root_dir = WindowsPath('D:/pythonProjects/KAG_Testing/GraphRAG') │ │\n",
      "│ │ skip_validation = False                                                 │ │\n",
      "│ │         verbose = False                                                 │ │\n",
      "│ └─────────────────────────────────────────────────────────────────────────┘ │\n",
      "│                                                                             │\n",
      "│ D:\\pythonProjects\\KAG_Testing\\graphragvenv\\lib\\site-packages\\graphrag\\cli\\i │\n",
      "│ ndex.py:149 in _run_index                                                   │\n",
      "│                                                                             │\n",
      "│   146 │   config.reporting.base_dir = (                                     │\n",
      "│   147 │   │   str(output_dir) if output_dir else config.reporting.base_dir  │\n",
      "│   148 │   )                                                                 │\n",
      "│ > 149 │   resolve_paths(config, run_id)                                     │\n",
      "│   150 │                                                                     │\n",
      "│   151 │   if not cache:                                                     │\n",
      "│   152 │   │   config.cache.type = CacheType.none                            │\n",
      "│                                                                             │\n",
      "│ ┌──────────────────────────────── locals ─────────────────────────────────┐ │\n",
      "│ │           cache = True                                                  │ │\n",
      "│ │          config = GraphRagConfig(                                       │ │\n",
      "│ │                   │   llm=LLMParameters(                                │ │\n",
      "│ │                   │   │                                                 │ │\n",
      "│ │                   api_key='FGH7P5rBJafjdYizJNC38PRxscCX8lYD5I5ddEZy2Gy… │ │\n",
      "│ │                   │   │   type=\"openai_chat\",                           │ │\n",
      "│ │                   │   │   encoding_model='cl100k_base',                 │ │\n",
      "│ │                   │   │   model='gpt-4-turbo-preview',                  │ │\n",
      "│ │                   │   │   max_tokens=4000,                              │ │\n",
      "│ │                   │   │   temperature=0.0,                              │ │\n",
      "│ │                   │   │   top_p=1.0,                                    │ │\n",
      "│ │                   │   │   n=1,                                          │ │\n",
      "│ │                   │   │   frequency_penalty=0.0,                        │ │\n",
      "│ │                   │   │   presence_penalty=0.0,                         │ │\n",
      "│ │                   │   │   request_timeout=180.0,                        │ │\n",
      "│ │                   │   │   api_base=None,                                │ │\n",
      "│ │                   │   │   api_version=None,                             │ │\n",
      "│ │                   │   │   organization=None,                            │ │\n",
      "│ │                   │   │   proxy=None,                                   │ │\n",
      "│ │                   │   │   audience=None,                                │ │\n",
      "│ │                   │   │   deployment_name=None,                         │ │\n",
      "│ │                   │   │   model_supports_json=None,                     │ │\n",
      "│ │                   │   │   tokens_per_minute=0,                          │ │\n",
      "│ │                   │   │   requests_per_minute=0,                        │ │\n",
      "│ │                   │   │   max_retries=10,                               │ │\n",
      "│ │                   │   │   max_retry_wait=10.0,                          │ │\n",
      "│ │                   │   │   sleep_on_rate_limit_recommendation=True,      │ │\n",
      "│ │                   │   │   concurrent_requests=25,                       │ │\n",
      "│ │                   │   │   responses=None                                │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   parallelization=ParallelizationParameters(        │ │\n",
      "│ │                   │   │   stagger=0.3,                                  │ │\n",
      "│ │                   │   │   num_threads=50                                │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   async_mode=<AsyncType.Threaded: 'threaded'>,      │ │\n",
      "│ │                   │                                                     │ │\n",
      "│ │                   root_dir='D:\\\\pythonProjects\\\\KAG_Testing\\\\GraphRAG', │ │\n",
      "│ │                   │   reporting=ReportingConfig(                        │ │\n",
      "│ │                   │   │   type=\"file\",                                  │ │\n",
      "│ │                   │   │                                                 │ │\n",
      "│ │                   base_dir='D:\\\\pythonProjects\\\\KAG_Testing\\\\GraphRAG\\… │ │\n",
      "│ │                   │   │   connection_string=None,                       │ │\n",
      "│ │                   │   │   container_name=None,                          │ │\n",
      "│ │                   │   │   storage_account_blob_url=None                 │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   storage=StorageConfig(                            │ │\n",
      "│ │                   │   │   type=\"file\",                                  │ │\n",
      "│ │                   │   │                                                 │ │\n",
      "│ │                   base_dir='D:\\\\pythonProjects\\\\KAG_Testing\\\\GraphRAG\\… │ │\n",
      "│ │                   │   │   connection_string=None,                       │ │\n",
      "│ │                   │   │   container_name=None,                          │ │\n",
      "│ │                   │   │   storage_account_blob_url=None,                │ │\n",
      "│ │                   │   │   cosmosdb_account_url=None                     │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   update_index_storage=None,                        │ │\n",
      "│ │                   │   cache=CacheConfig(                                │ │\n",
      "│ │                   │   │   type=\"file\",                                  │ │\n",
      "│ │                   │   │   base_dir='cache',                             │ │\n",
      "│ │                   │   │   connection_string=None,                       │ │\n",
      "│ │                   │   │   container_name=None,                          │ │\n",
      "│ │                   │   │   storage_account_blob_url=None,                │ │\n",
      "│ │                   │   │   cosmosdb_account_url=None                     │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   input=InputConfig(                                │ │\n",
      "│ │                   │   │   type=\"file\",                                  │ │\n",
      "│ │                   │   │   file_type=\"text\",                             │ │\n",
      "│ │                   │   │   base_dir='input',                             │ │\n",
      "│ │                   │   │   connection_string=None,                       │ │\n",
      "│ │                   │   │   storage_account_blob_url=None,                │ │\n",
      "│ │                   │   │   container_name=None,                          │ │\n",
      "│ │                   │   │   encoding='utf-8',                             │ │\n",
      "│ │                   │   │   file_pattern='.*\\\\.csv$',                     │ │\n",
      "│ │                   │   │   file_filter=None,                             │ │\n",
      "│ │                   │   │   source_column=None,                           │ │\n",
      "│ │                   │   │   timestamp_column=None,                        │ │\n",
      "│ │                   │   │   timestamp_format=None,                        │ │\n",
      "│ │                   │   │   text_column='text',                           │ │\n",
      "│ │                   │   │   title_column=None,                            │ │\n",
      "│ │                   │   │   document_attribute_columns=[]                 │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   embed_graph=EmbedGraphConfig(                     │ │\n",
      "│ │                   │   │   enabled=False,                                │ │\n",
      "│ │                   │   │   dimensions=1536,                              │ │\n",
      "│ │                   │   │   num_walks=10,                                 │ │\n",
      "│ │                   │   │   walk_length=40,                               │ │\n",
      "│ │                   │   │   window_size=2,                                │ │\n",
      "│ │                   │   │   iterations=3,                                 │ │\n",
      "│ │                   │   │   random_seed=597832,                           │ │\n",
      "│ │                   │   │   use_lcc=True                                  │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   embeddings=TextEmbeddingConfig(                   │ │\n",
      "│ │                   │   │   llm=LLMParameters(                            │ │\n",
      "│ │                   │   │   │                                             │ │\n",
      "│ │                   api_key='FGH7P5rBJafjdYizJNC38PRxscCX8lYD5I5ddEZy2Gy… │ │\n",
      "│ │                   │   │   │   type=\"openai_embedding\",                  │ │\n",
      "│ │                   │   │   │   encoding_model='cl100k_base',             │ │\n",
      "│ │                   │   │   │   model='text-embedding-3-small',           │ │\n",
      "│ │                   │   │   │   max_tokens=4000,                          │ │\n",
      "│ │                   │   │   │   temperature=0,                            │ │\n",
      "│ │                   │   │   │   top_p=1,                                  │ │\n",
      "│ │                   │   │   │   n=1,                                      │ │\n",
      "│ │                   │   │   │   frequency_penalty=0.0,                    │ │\n",
      "│ │                   │   │   │   presence_penalty=0.0,                     │ │\n",
      "│ │                   │   │   │   request_timeout=180.0,                    │ │\n",
      "│ │                   │   │   │   api_base=None,                            │ │\n",
      "│ │                   │   │   │   api_version=None,                         │ │\n",
      "│ │                   │   │   │   organization=None,                        │ │\n",
      "│ │                   │   │   │   proxy=None,                               │ │\n",
      "│ │                   │   │   │   audience=None,                            │ │\n",
      "│ │                   │   │   │   deployment_name=None,                     │ │\n",
      "│ │                   │   │   │   model_supports_json=None,                 │ │\n",
      "│ │                   │   │   │   tokens_per_minute=0,                      │ │\n",
      "│ │                   │   │   │   requests_per_minute=0,                    │ │\n",
      "│ │                   │   │   │   max_retries=10,                           │ │\n",
      "│ │                   │   │   │   max_retry_wait=10.0,                      │ │\n",
      "│ │                   │   │   │   sleep_on_rate_limit_recommendation=True,  │ │\n",
      "│ │                   │   │   │   concurrent_requests=25,                   │ │\n",
      "│ │                   │   │   │   responses=None                            │ │\n",
      "│ │                   │   │   ),                                            │ │\n",
      "│ │                   │   │   parallelization=ParallelizationParameters(    │ │\n",
      "│ │                   │   │   │   stagger=0.3,                              │ │\n",
      "│ │                   │   │   │   num_threads=50                            │ │\n",
      "│ │                   │   │   ),                                            │ │\n",
      "│ │                   │   │   async_mode=<AsyncType.Threaded: 'threaded'>,  │ │\n",
      "│ │                   │   │   batch_size=16,                                │ │\n",
      "│ │                   │   │   batch_max_tokens=8191,                        │ │\n",
      "│ │                   │   │   target=\"required\",                            │ │\n",
      "│ │                   │   │   skip=[],                                      │ │\n",
      "│ │                   │   │   vector_store=None,                            │ │\n",
      "│ │                   │   │   strategy=None                                 │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   chunks=ChunkingConfig(                            │ │\n",
      "│ │                   │   │   size=1200,                                    │ │\n",
      "│ │                   │   │   overlap=100,                                  │ │\n",
      "│ │                   │   │   group_by_columns=['id'],                      │ │\n",
      "│ │                   │   │   strategy=\"tokens\",                            │ │\n",
      "│ │                   │   │   encoding_model='cl100k_base'                  │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   snapshots=SnapshotsConfig(                        │ │\n",
      "│ │                   │   │   embeddings=False,                             │ │\n",
      "│ │                   │   │   graphml=False,                                │ │\n",
      "│ │                   │   │   transient=False                               │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   entity_extraction=EntityExtractionConfig(         │ │\n",
      "│ │                   │   │   llm=LLMParameters(                            │ │\n",
      "│ │                   │   │   │                                             │ │\n",
      "│ │                   api_key='FGH7P5rBJafjdYizJNC38PRxscCX8lYD5I5ddEZy2Gy… │ │\n",
      "│ │                   │   │   │   type=\"openai_chat\",                       │ │\n",
      "│ │                   │   │   │   encoding_model='cl100k_base',             │ │\n",
      "│ │                   │   │   │   model='gpt-4-turbo-preview',              │ │\n",
      "│ │                   │   │   │   max_tokens=4000,                          │ │\n",
      "│ │                   │   │   │   temperature=0.0,                          │ │\n",
      "│ │                   │   │   │   top_p=1.0,                                │ │\n",
      "│ │                   │   │   │   n=1,                                      │ │\n",
      "│ │                   │   │   │   frequency_penalty=0.0,                    │ │\n",
      "│ │                   │   │   │   presence_penalty=0.0,                     │ │\n",
      "│ │                   │   │   │   request_timeout=180.0,                    │ │\n",
      "│ │                   │   │   │   api_base=None,                            │ │\n",
      "│ │                   │   │   │   api_version=None,                         │ │\n",
      "│ │                   │   │   │   organization=None,                        │ │\n",
      "│ │                   │   │   │   proxy=None,                               │ │\n",
      "│ │                   │   │   │   audience=None,                            │ │\n",
      "│ │                   │   │   │   deployment_name=None,                     │ │\n",
      "│ │                   │   │   │   model_supports_json=None,                 │ │\n",
      "│ │                   │   │   │   tokens_per_minute=0,                      │ │\n",
      "│ │                   │   │   │   requests_per_minute=0,                    │ │\n",
      "│ │                   │   │   │   max_retries=10,                           │ │\n",
      "│ │                   │   │   │   max_retry_wait=10.0,                      │ │\n",
      "│ │                   │   │   │   sleep_on_rate_limit_recommendation=True,  │ │\n",
      "│ │                   │   │   │   concurrent_requests=25,                   │ │\n",
      "│ │                   │   │   │   responses=None                            │ │\n",
      "│ │                   │   │   ),                                            │ │\n",
      "│ │                   │   │   parallelization=ParallelizationParameters(    │ │\n",
      "│ │                   │   │   │   stagger=0.3,                              │ │\n",
      "│ │                   │   │   │   num_threads=50                            │ │\n",
      "│ │                   │   │   ),                                            │ │\n",
      "│ │                   │   │   async_mode=<AsyncType.Threaded: 'threaded'>,  │ │\n",
      "│ │                   │   │   prompt=None,                                  │ │\n",
      "│ │                   │   │   entity_types=[                                │ │\n",
      "│ │                   │   │   │   'organization',                           │ │\n",
      "│ │                   │   │   │   'person',                                 │ │\n",
      "│ │                   │   │   │   'geo',                                    │ │\n",
      "│ │                   │   │   │   'event'                                   │ │\n",
      "│ │                   │   │   ],                                            │ │\n",
      "│ │                   │   │   max_gleanings=1,                              │ │\n",
      "│ │                   │   │   strategy=None,                                │ │\n",
      "│ │                   │   │   encoding_model='cl100k_base'                  │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │                                                     │ │\n",
      "│ │                   summarize_descriptions=SummarizeDescriptionsConfig(   │ │\n",
      "│ │                   │   │   llm=LLMParameters(                            │ │\n",
      "│ │                   │   │   │                                             │ │\n",
      "│ │                   api_key='FGH7P5rBJafjdYizJNC38PRxscCX8lYD5I5ddEZy2Gy… │ │\n",
      "│ │                   │   │   │   type=\"openai_chat\",                       │ │\n",
      "│ │                   │   │   │   encoding_model='cl100k_base',             │ │\n",
      "│ │                   │   │   │   model='gpt-4-turbo-preview',              │ │\n",
      "│ │                   │   │   │   max_tokens=4000,                          │ │\n",
      "│ │                   │   │   │   temperature=0.0,                          │ │\n",
      "│ │                   │   │   │   top_p=1.0,                                │ │\n",
      "│ │                   │   │   │   n=1,                                      │ │\n",
      "│ │                   │   │   │   frequency_penalty=0.0,                    │ │\n",
      "│ │                   │   │   │   presence_penalty=0.0,                     │ │\n",
      "│ │                   │   │   │   request_timeout=180.0,                    │ │\n",
      "│ │                   │   │   │   api_base=None,                            │ │\n",
      "│ │                   │   │   │   api_version=None,                         │ │\n",
      "│ │                   │   │   │   organization=None,                        │ │\n",
      "│ │                   │   │   │   proxy=None,                               │ │\n",
      "│ │                   │   │   │   audience=None,                            │ │\n",
      "│ │                   │   │   │   deployment_name=None,                     │ │\n",
      "│ │                   │   │   │   model_supports_json=None,                 │ │\n",
      "│ │                   │   │   │   tokens_per_minute=0,                      │ │\n",
      "│ │                   │   │   │   requests_per_minute=0,                    │ │\n",
      "│ │                   │   │   │   max_retries=10,                           │ │\n",
      "│ │                   │   │   │   max_retry_wait=10.0,                      │ │\n",
      "│ │                   │   │   │   sleep_on_rate_limit_recommendation=True,  │ │\n",
      "│ │                   │   │   │   concurrent_requests=25,                   │ │\n",
      "│ │                   │   │   │   responses=None                            │ │\n",
      "│ │                   │   │   ),                                            │ │\n",
      "│ │                   │   │   parallelization=ParallelizationParameters(    │ │\n",
      "│ │                   │   │   │   stagger=0.3,                              │ │\n",
      "│ │                   │   │   │   num_threads=50                            │ │\n",
      "│ │                   │   │   ),                                            │ │\n",
      "│ │                   │   │   async_mode=<AsyncType.Threaded: 'threaded'>,  │ │\n",
      "│ │                   │   │   prompt=None,                                  │ │\n",
      "│ │                   │   │   max_length=500,                               │ │\n",
      "│ │                   │   │   strategy=None                                 │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   community_reports=CommunityReportsConfig(         │ │\n",
      "│ │                   │   │   llm=LLMParameters(                            │ │\n",
      "│ │                   │   │   │                                             │ │\n",
      "│ │                   api_key='FGH7P5rBJafjdYizJNC38PRxscCX8lYD5I5ddEZy2Gy… │ │\n",
      "│ │                   │   │   │   type=\"openai_chat\",                       │ │\n",
      "│ │                   │   │   │   encoding_model='cl100k_base',             │ │\n",
      "│ │                   │   │   │   model='gpt-4-turbo-preview',              │ │\n",
      "│ │                   │   │   │   max_tokens=4000,                          │ │\n",
      "│ │                   │   │   │   temperature=0.0,                          │ │\n",
      "│ │                   │   │   │   top_p=1.0,                                │ │\n",
      "│ │                   │   │   │   n=1,                                      │ │\n",
      "│ │                   │   │   │   frequency_penalty=0.0,                    │ │\n",
      "│ │                   │   │   │   presence_penalty=0.0,                     │ │\n",
      "│ │                   │   │   │   request_timeout=180.0,                    │ │\n",
      "│ │                   │   │   │   api_base=None,                            │ │\n",
      "│ │                   │   │   │   api_version=None,                         │ │\n",
      "│ │                   │   │   │   organization=None,                        │ │\n",
      "│ │                   │   │   │   proxy=None,                               │ │\n",
      "│ │                   │   │   │   audience=None,                            │ │\n",
      "│ │                   │   │   │   deployment_name=None,                     │ │\n",
      "│ │                   │   │   │   model_supports_json=None,                 │ │\n",
      "│ │                   │   │   │   tokens_per_minute=0,                      │ │\n",
      "│ │                   │   │   │   requests_per_minute=0,                    │ │\n",
      "│ │                   │   │   │   max_retries=10,                           │ │\n",
      "│ │                   │   │   │   max_retry_wait=10.0,                      │ │\n",
      "│ │                   │   │   │   sleep_on_rate_limit_recommendation=True,  │ │\n",
      "│ │                   │   │   │   concurrent_requests=25,                   │ │\n",
      "│ │                   │   │   │   responses=None                            │ │\n",
      "│ │                   │   │   ),                                            │ │\n",
      "│ │                   │   │   parallelization=ParallelizationParameters(    │ │\n",
      "│ │                   │   │   │   stagger=0.3,                              │ │\n",
      "│ │                   │   │   │   num_threads=50                            │ │\n",
      "│ │                   │   │   ),                                            │ │\n",
      "│ │                   │   │   async_mode=<AsyncType.Threaded: 'threaded'>,  │ │\n",
      "│ │                   │   │   prompt=None,                                  │ │\n",
      "│ │                   │   │   max_length=2000,                              │ │\n",
      "│ │                   │   │   max_input_length=8000,                        │ │\n",
      "│ │                   │   │   strategy=None                                 │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   claim_extraction=ClaimExtractionConfig(           │ │\n",
      "│ │                   │   │   llm=LLMParameters(                            │ │\n",
      "│ │                   │   │   │                                             │ │\n",
      "│ │                   api_key='FGH7P5rBJafjdYizJNC38PRxscCX8lYD5I5ddEZy2Gy… │ │\n",
      "│ │                   │   │   │   type=\"openai_chat\",                       │ │\n",
      "│ │                   │   │   │   encoding_model='cl100k_base',             │ │\n",
      "│ │                   │   │   │   model='gpt-4-turbo-preview',              │ │\n",
      "│ │                   │   │   │   max_tokens=4000,                          │ │\n",
      "│ │                   │   │   │   temperature=0.0,                          │ │\n",
      "│ │                   │   │   │   top_p=1.0,                                │ │\n",
      "│ │                   │   │   │   n=1,                                      │ │\n",
      "│ │                   │   │   │   frequency_penalty=0.0,                    │ │\n",
      "│ │                   │   │   │   presence_penalty=0.0,                     │ │\n",
      "│ │                   │   │   │   request_timeout=180.0,                    │ │\n",
      "│ │                   │   │   │   api_base=None,                            │ │\n",
      "│ │                   │   │   │   api_version=None,                         │ │\n",
      "│ │                   │   │   │   organization=None,                        │ │\n",
      "│ │                   │   │   │   proxy=None,                               │ │\n",
      "│ │                   │   │   │   audience=None,                            │ │\n",
      "│ │                   │   │   │   deployment_name=None,                     │ │\n",
      "│ │                   │   │   │   model_supports_json=None,                 │ │\n",
      "│ │                   │   │   │   tokens_per_minute=0,                      │ │\n",
      "│ │                   │   │   │   requests_per_minute=0,                    │ │\n",
      "│ │                   │   │   │   max_retries=10,                           │ │\n",
      "│ │                   │   │   │   max_retry_wait=10.0,                      │ │\n",
      "│ │                   │   │   │   sleep_on_rate_limit_recommendation=True,  │ │\n",
      "│ │                   │   │   │   concurrent_requests=25,                   │ │\n",
      "│ │                   │   │   │   responses=None                            │ │\n",
      "│ │                   │   │   ),                                            │ │\n",
      "│ │                   │   │   parallelization=ParallelizationParameters(    │ │\n",
      "│ │                   │   │   │   stagger=0.3,                              │ │\n",
      "│ │                   │   │   │   num_threads=50                            │ │\n",
      "│ │                   │   │   ),                                            │ │\n",
      "│ │                   │   │   async_mode=<AsyncType.Threaded: 'threaded'>,  │ │\n",
      "│ │                   │   │   enabled=False,                                │ │\n",
      "│ │                   │   │   prompt=None,                                  │ │\n",
      "│ │                   │   │   description='Any claims or facts that could   │ │\n",
      "│ │                   be relevant to information discovery.',               │ │\n",
      "│ │                   │   │   max_gleanings=1,                              │ │\n",
      "│ │                   │   │   strategy=None,                                │ │\n",
      "│ │                   │   │   encoding_model='cl100k_base'                  │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   cluster_graph=ClusterGraphConfig(                 │ │\n",
      "│ │                   │   │   max_cluster_size=10,                          │ │\n",
      "│ │                   │   │   use_lcc=True,                                 │ │\n",
      "│ │                   │   │   seed=3735928559                               │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   umap=UmapConfig(enabled=False),                   │ │\n",
      "│ │                   │   local_search=LocalSearchConfig(                   │ │\n",
      "│ │                   │   │   prompt=None,                                  │ │\n",
      "│ │                   │   │   text_unit_prop=0.5,                           │ │\n",
      "│ │                   │   │   community_prop=0.15,                          │ │\n",
      "│ │                   │   │   conversation_history_max_turns=5,             │ │\n",
      "│ │                   │   │   top_k_entities=10,                            │ │\n",
      "│ │                   │   │   top_k_relationships=10,                       │ │\n",
      "│ │                   │   │   temperature=0.0,                              │ │\n",
      "│ │                   │   │   top_p=1.0,                                    │ │\n",
      "│ │                   │   │   n=1,                                          │ │\n",
      "│ │                   │   │   max_tokens=12000,                             │ │\n",
      "│ │                   │   │   llm_max_tokens=2000                           │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   global_search=GlobalSearchConfig(                 │ │\n",
      "│ │                   │   │   map_prompt=None,                              │ │\n",
      "│ │                   │   │   reduce_prompt=None,                           │ │\n",
      "│ │                   │   │   knowledge_prompt=None,                        │ │\n",
      "│ │                   │   │   temperature=0.0,                              │ │\n",
      "│ │                   │   │   top_p=1.0,                                    │ │\n",
      "│ │                   │   │   n=1,                                          │ │\n",
      "│ │                   │   │   max_tokens=12000,                             │ │\n",
      "│ │                   │   │   data_max_tokens=12000,                        │ │\n",
      "│ │                   │   │   map_max_tokens=1000,                          │ │\n",
      "│ │                   │   │   reduce_max_tokens=2000,                       │ │\n",
      "│ │                   │   │   concurrency=32,                               │ │\n",
      "│ │                   │   │   dynamic_search_llm='gpt-4o-mini',             │ │\n",
      "│ │                   │   │   dynamic_search_threshold=1,                   │ │\n",
      "│ │                   │   │   dynamic_search_keep_parent=False,             │ │\n",
      "│ │                   │   │   dynamic_search_num_repeats=1,                 │ │\n",
      "│ │                   │   │   dynamic_search_use_summary=False,             │ │\n",
      "│ │                   │   │   dynamic_search_concurrent_coroutines=16,      │ │\n",
      "│ │                   │   │   dynamic_search_max_level=2                    │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   drift_search=DRIFTSearchConfig(                   │ │\n",
      "│ │                   │   │   prompt=None,                                  │ │\n",
      "│ │                   │   │   temperature=0.0,                              │ │\n",
      "│ │                   │   │   top_p=1.0,                                    │ │\n",
      "│ │                   │   │   n=3,                                          │ │\n",
      "│ │                   │   │   max_tokens=12000,                             │ │\n",
      "│ │                   │   │   data_max_tokens=12000,                        │ │\n",
      "│ │                   │   │   concurrency=32,                               │ │\n",
      "│ │                   │   │   drift_k_followups=20,                         │ │\n",
      "│ │                   │   │   primer_folds=5,                               │ │\n",
      "│ │                   │   │   primer_llm_max_tokens=12000,                  │ │\n",
      "│ │                   │   │   n_depth=3,                                    │ │\n",
      "│ │                   │   │   local_search_text_unit_prop=0.9,              │ │\n",
      "│ │                   │   │   local_search_community_prop=0.1,              │ │\n",
      "│ │                   │   │   local_search_top_k_mapped_entities=10,        │ │\n",
      "│ │                   │   │   local_search_top_k_relationships=10,          │ │\n",
      "│ │                   │   │   local_search_max_data_tokens=12000,           │ │\n",
      "│ │                   │   │   local_search_temperature=0.0,                 │ │\n",
      "│ │                   │   │   local_search_top_p=1.0,                       │ │\n",
      "│ │                   │   │   local_search_n=1,                             │ │\n",
      "│ │                   │   │   local_search_llm_max_gen_tokens=2000          │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   basic_search=BasicSearchConfig(                   │ │\n",
      "│ │                   │   │   prompt=None,                                  │ │\n",
      "│ │                   │   │   text_unit_prop=0.5,                           │ │\n",
      "│ │                   │   │   conversation_history_max_turns=5,             │ │\n",
      "│ │                   │   │   temperature=0.0,                              │ │\n",
      "│ │                   │   │   top_p=1.0,                                    │ │\n",
      "│ │                   │   │   n=1,                                          │ │\n",
      "│ │                   │   │   max_tokens=12000,                             │ │\n",
      "│ │                   │   │   llm_max_tokens=2000                           │ │\n",
      "│ │                   │   ),                                                │ │\n",
      "│ │                   │   encoding_model='cl100k_base',                     │ │\n",
      "│ │                   │   skip_workflows=[]                                 │ │\n",
      "│ │                   )                                                     │ │\n",
      "│ │         dry_run = False                                                 │ │\n",
      "│ │          logger = <LoggerType.RICH: 'rich'>                             │ │\n",
      "│ │      memprofile = False                                                 │ │\n",
      "│ │      output_dir = None                                                  │ │\n",
      "│ │ progress_logger = <graphrag.logger.rich_progress.RichProgressLogger     │ │\n",
      "│ │                   object at 0x0000015DD8416170>                         │ │\n",
      "│ │          resume = None                                                  │ │\n",
      "│ │          run_id = '20250113-161436'                                     │ │\n",
      "│ │ skip_validation = False                                                 │ │\n",
      "│ │         verbose = False                                                 │ │\n",
      "│ └─────────────────────────────────────────────────────────────────────────┘ │\n",
      "│                                                                             │\n",
      "│ D:\\pythonProjects\\KAG_Testing\\graphragvenv\\lib\\site-packages\\graphrag\\confi │\n",
      "│ g\\resolve_path.py:210 in resolve_paths                                      │\n",
      "│                                                                             │\n",
      "│   207 │                                                                     │\n",
      "│   208 │   # TODO: must update filepath of lancedb (if used) until the new c │\n",
      "│   209 │   # TODO: remove the type ignore annotations below once the new con │\n",
      "│ > 210 │   vector_store_type = config.embeddings.vector_store[\"type\"]  # typ │\n",
      "│   211 │   if vector_store_type == VectorStoreType.LanceDB:                  │\n",
      "│   212 │   │   db_uri = config.embeddings.vector_store[\"db_uri\"]  # type: ig │\n",
      "│   213 │   │   lancedb_dir = Path(config.root_dir).resolve() / db_uri        │\n",
      "│                                                                             │\n",
      "│ ┌──────────────────────────────── locals ─────────────────────────────────┐ │\n",
      "│ │                     config = GraphRagConfig(                            │ │\n",
      "│ │                              │   llm=LLMParameters(                     │ │\n",
      "│ │                              │   │                                      │ │\n",
      "│ │                              api_key='FGH7P5rBJafjdYizJNC38PRxscCX8lYD… │ │\n",
      "│ │                              │   │   type=\"openai_chat\",                │ │\n",
      "│ │                              │   │   encoding_model='cl100k_base',      │ │\n",
      "│ │                              │   │   model='gpt-4-turbo-preview',       │ │\n",
      "│ │                              │   │   max_tokens=4000,                   │ │\n",
      "│ │                              │   │   temperature=0.0,                   │ │\n",
      "│ │                              │   │   top_p=1.0,                         │ │\n",
      "│ │                              │   │   n=1,                               │ │\n",
      "│ │                              │   │   frequency_penalty=0.0,             │ │\n",
      "│ │                              │   │   presence_penalty=0.0,              │ │\n",
      "│ │                              │   │   request_timeout=180.0,             │ │\n",
      "│ │                              │   │   api_base=None,                     │ │\n",
      "│ │                              │   │   api_version=None,                  │ │\n",
      "│ │                              │   │   organization=None,                 │ │\n",
      "│ │                              │   │   proxy=None,                        │ │\n",
      "│ │                              │   │   audience=None,                     │ │\n",
      "│ │                              │   │   deployment_name=None,              │ │\n",
      "│ │                              │   │   model_supports_json=None,          │ │\n",
      "│ │                              │   │   tokens_per_minute=0,               │ │\n",
      "│ │                              │   │   requests_per_minute=0,             │ │\n",
      "│ │                              │   │   max_retries=10,                    │ │\n",
      "│ │                              │   │   max_retry_wait=10.0,               │ │\n",
      "│ │                              │   │                                      │ │\n",
      "│ │                              sleep_on_rate_limit_recommendation=True,   │ │\n",
      "│ │                              │   │   concurrent_requests=25,            │ │\n",
      "│ │                              │   │   responses=None                     │ │\n",
      "│ │                              │   ),                                     │ │\n",
      "│ │                              │                                          │ │\n",
      "│ │                              parallelization=ParallelizationParameters( │ │\n",
      "│ │                              │   │   stagger=0.3,                       │ │\n",
      "│ │                              │   │   num_threads=50                     │ │\n",
      "│ │                              │   ),                                     │ │\n",
      "│ │                              │   async_mode=<AsyncType.Threaded:        │ │\n",
      "│ │                              'threaded'>,                               │ │\n",
      "│ │                              │                                          │ │\n",
      "│ │                              root_dir='D:\\\\pythonProjects\\\\KAG_Testing… │ │\n",
      "│ │                              │   reporting=ReportingConfig(             │ │\n",
      "│ │                              │   │   type=\"file\",                       │ │\n",
      "│ │                              │   │                                      │ │\n",
      "│ │                              base_dir='D:\\\\pythonProjects\\\\KAG_Testing… │ │\n",
      "│ │                              │   │   connection_string=None,            │ │\n",
      "│ │                              │   │   container_name=None,               │ │\n",
      "│ │                              │   │   storage_account_blob_url=None      │ │\n",
      "│ │                              │   ),                                     │ │\n",
      "│ │                              │   storage=StorageConfig(                 │ │\n",
      "│ │                              │   │   type=\"file\",                       │ │\n",
      "│ │                              │   │                                      │ │\n",
      "│ │                              base_dir='D:\\\\pythonProjects\\\\KAG_Testing… │ │\n",
      "│ │                              │   │   connection_string=None,            │ │\n",
      "│ │                              │   │   container_name=None,               │ │\n",
      "│ │                              │   │   storage_account_blob_url=None,     │ │\n",
      "│ │                              │   │   cosmosdb_account_url=None          │ │\n",
      "│ │                              │   ),                                     │ │\n",
      "│ │                              │   update_index_storage=None,             │ │\n",
      "│ │                              │   cache=CacheConfig(                     │ │\n",
      "│ │                              │   │   type=\"file\",                       │ │\n",
      "│ │                              │   │   base_dir='cache',                  │ │\n",
      "│ │                              │   │   connection_string=None,            │ │\n",
      "│ │                              │   │   container_name=None,               │ │\n",
      "│ │                              │   │   storage_account_blob_url=None,     │ │\n",
      "│ │                              │   │   cosmosdb_account_url=None          │ │\n",
      "│ │                              │   ),                                     │ │\n",
      "│ │                              │   input=InputConfig(                     │ │\n",
      "│ │                              │   │   type=\"file\",                       │ │\n",
      "│ │                              │   │   file_type=\"text\",                  │ │\n",
      "│ │                              │   │   base_dir='input',                  │ │\n",
      "│ │                              │   │   connection_string=None,            │ │\n",
      "│ │                              │   │   storage_account_blob_url=None,     │ │\n",
      "│ │                              │   │   container_name=None,               │ │\n",
      "│ │                              │   │   encoding='utf-8',                  │ │\n",
      "│ │                              │   │   file_pattern='.*\\\\.csv$',          │ │\n",
      "│ │                              │   │   file_filter=None,                  │ │\n",
      "│ │                              │   │   source_column=None,                │ │\n",
      "│ │                              │   │   timestamp_column=None,             │ │\n",
      "│ │                              │   │   timestamp_format=None,             │ │\n",
      "│ │                              │   │   text_column='text',                │ │\n",
      "│ │                              │   │   title_column=None,                 │ │\n",
      "│ │                              │   │   document_attribute_columns=[]      │ │\n",
      "│ │                              │   ),                                     │ │\n",
      "│ │                              │   embed_graph=EmbedGraphConfig(          │ │\n",
      "│ │                              │   │   enabled=False,                     │ │\n",
      "│ │                              │   │   dimensions=1536,                   │ │\n",
      "│ │                              │   │   num_walks=10,                      │ │\n",
      "│ │                              │   │   walk_length=40,                    │ │\n",
      "│ │                              │   │   window_size=2,                     │ │\n",
      "│ │                              │   │   iterations=3,                      │ │\n",
      "│ │                              │   │   random_seed=597832,                │ │\n",
      "│ │                              │   │   use_lcc=True                       │ │\n",
      "│ │                              │   ),                                     │ │\n",
      "│ │                              │   embeddings=TextEmbeddingConfig(        │ │\n",
      "│ │                              │   │   llm=LLMParameters(                 │ │\n",
      "│ │                              │   │   │                                  │ │\n",
      "│ │                              api_key='FGH7P5rBJafjdYizJNC38PRxscCX8lYD… │ │\n",
      "│ │                              │   │   │   type=\"openai_embedding\",       │ │\n",
      "│ │                              │   │   │   encoding_model='cl100k_base',  │ │\n",
      "│ │                              │   │   │                                  │ │\n",
      "│ │                              model='text-embedding-3-small',            │ │\n",
      "│ │                              │   │   │   max_tokens=4000,               │ │\n",
      "│ │                              │   │   │   temperature=0,                 │ │\n",
      "│ │                              │   │   │   top_p=1,                       │ │\n",
      "│ │                              │   │   │   n=1,                           │ │\n",
      "│ │                              │   │   │   frequency_penalty=0.0,         │ │\n",
      "│ │                              │   │   │   presence_penalty=0.0,          │ │\n",
      "│ │                              │   │   │   request_timeout=180.0,         │ │\n",
      "│ │                              │   │   │   api_base=None,                 │ │\n",
      "│ │                              │   │   │   api_version=None,              │ │\n",
      "│ │                              │   │   │   organization=None,             │ │\n",
      "│ │                              │   │   │   proxy=None,                    │ │\n",
      "│ │                              │   │   │   audience=None,                 │ │\n",
      "│ │                              │   │   │   deployment_name=None,          │ │\n",
      "│ │                              │   │   │   model_supports_json=None,      │ │\n",
      "│ │                              │   │   │   tokens_per_minute=0,           │ │\n",
      "│ │                              │   │   │   requests_per_minute=0,         │ │\n",
      "│ │                              │   │   │   max_retries=10,                │ │\n",
      "│ │                              │   │   │   max_retry_wait=10.0,           │ │\n",
      "│ │                              │   │   │                                  │ │\n",
      "│ │                              sleep_on_rate_limit_recommendation=True,   │ │\n",
      "│ │                              │   │   │   concurrent_requests=25,        │ │\n",
      "│ │                              │   │   │   responses=None                 │ │\n",
      "│ │                              │   │   ),                                 │ │\n",
      "│ │                              │   │                                      │ │\n",
      "│ │                              parallelization=ParallelizationParameters( │ │\n",
      "│ │                              │   │   │   stagger=0.3,                   │ │\n",
      "│ │                              │   │   │   num_threads=50                 │ │\n",
      "│ │                              │   │   ),                                 │ │\n",
      "│ │                              │   │   async_mode=<AsyncType.Threaded:    │ │\n",
      "│ │                              'threaded'>,                               │ │\n",
      "│ │                              │   │   batch_size=16,                     │ │\n",
      "│ │                              │   │   batch_max_tokens=8191,             │ │\n",
      "│ │                              │   │   target=\"required\",                 │ │\n",
      "│ │                              │   │   skip=[],                           │ │\n",
      "│ │                              │   │   vector_store=None,                 │ │\n",
      "│ │                              │   │   strategy=None                      │ │\n",
      "│ │                              │   ),                                     │ │\n",
      "│ │                              │   chunks=ChunkingConfig(                 │ │\n",
      "│ │                              │   │   size=1200,                         │ │\n",
      "│ │                              │   │   overlap=100,                       │ │\n",
      "│ │                              │   │   group_by_columns=['id'],           │ │\n",
      "│ │                              │   │   strategy=\"tokens\",                 │ │\n",
      "│ │                              │   │   encoding_model='cl100k_base'       │ │\n",
      "│ │                              │   ),                                     │ │\n",
      "│ │                              │   snapshots=SnapshotsConfig(             │ │\n",
      "│ │                              │   │   embeddings=False,                  │ │\n",
      "│ │                              │   │   graphml=False,                     │ │\n",
      "│ │                              │   │   transient=False                    │ │\n",
      "│ │                              │   ),                                     │ │\n",
      "│ │                              │                                          │ │\n",
      "│ │                              entity_extraction=EntityExtractionConfig(  │ │\n",
      "│ │                              │   │   llm=LLMParameters(                 │ │\n",
      "│ │                              │   │   │                                  │ │\n",
      "│ │                              api_key='FGH7P5rBJafjdYizJNC38PRxscCX8lYD… │ │\n",
      "│ │                              │   │   │   type=\"openai_chat\",            │ │\n",
      "│ │                              │   │   │   encoding_model='cl100k_base',  │ │\n",
      "│ │                              │   │   │   model='gpt-4-turbo-preview',   │ │\n",
      "│ │                              │   │   │   max_tokens=4000,               │ │\n",
      "│ │                              │   │   │   temperature=0.0,               │ │\n",
      "│ │                              │   │   │   top_p=1.0,                     │ │\n",
      "│ │                              │   │   │   n=1,                           │ │\n",
      "│ │                              │   │   │   frequency_penalty=0.0,         │ │\n",
      "│ │                              │   │   │   presence_penalty=0.0,          │ │\n",
      "│ │                              │   │   │   request_timeout=180.0,         │ │\n",
      "│ │                              │   │   │   api_base=None,                 │ │\n",
      "│ │                              │   │   │   api_version=None,              │ │\n",
      "│ │                              │   │   │   organization=None,             │ │\n",
      "│ │                              │   │   │   proxy=None,                    │ │\n",
      "│ │                              │   │   │   audience=None,                 │ │\n",
      "│ │                              │   │   │   deployment_name=None,          │ │\n",
      "│ │                              │   │   │   model_supports_json=None,      │ │\n",
      "│ │                              │   │   │   tokens_per_minute=0,           │ │\n",
      "│ │                              │   │   │   requests_per_minute=0,         │ │\n",
      "│ │                              │   │   │   max_retries=10,                │ │\n",
      "│ │                              │   │   │   max_retry_wait=10.0,           │ │\n",
      "│ │                              │   │   │                                  │ │\n",
      "│ │                              sleep_on_rate_limit_recommendation=True,   │ │\n",
      "│ │                              │   │   │   concurrent_requests=25,        │ │\n",
      "│ │                              │   │   │   responses=None                 │ │\n",
      "│ │                              │   │   ),                                 │ │\n",
      "│ │                              │   │                                      │ │\n",
      "│ │                              parallelization=ParallelizationParameters( │ │\n",
      "│ │                              │   │   │   stagger=0.3,                   │ │\n",
      "│ │                              │   │   │   num_threads=50                 │ │\n",
      "│ │                              │   │   ),                                 │ │\n",
      "│ │                              │   │   async_mode=<AsyncType.Threaded:    │ │\n",
      "│ │                              'threaded'>,                               │ │\n",
      "│ │                              │   │   prompt=None,                       │ │\n",
      "│ │                              │   │   entity_types=[                     │ │\n",
      "│ │                              │   │   │   'organization',                │ │\n",
      "│ │                              │   │   │   'person',                      │ │\n",
      "│ │                              │   │   │   'geo',                         │ │\n",
      "│ │                              │   │   │   'event'                        │ │\n",
      "│ │                              │   │   ],                                 │ │\n",
      "│ │                              │   │   max_gleanings=1,                   │ │\n",
      "│ │                              │   │   strategy=None,                     │ │\n",
      "│ │                              │   │   encoding_model='cl100k_base'       │ │\n",
      "│ │                              │   ),                                     │ │\n",
      "│ │                              │                                          │ │\n",
      "│ │                              summarize_descriptions=SummarizeDescripti… │ │\n",
      "│ │                              │   │   llm=LLMParameters(                 │ │\n",
      "│ │                              │   │   │                                  │ │\n",
      "│ │                              api_key='FGH7P5rBJafjdYizJNC38PRxscCX8lYD… │ │\n",
      "│ │                              │   │   │   type=\"openai_chat\",            │ │\n",
      "│ │                              │   │   │   encoding_model='cl100k_base',  │ │\n",
      "│ │                              │   │   │   model='gpt-4-turbo-preview',   │ │\n",
      "│ │                              │   │   │   max_tokens=4000,               │ │\n",
      "│ │                              │   │   │   temperature=0.0,               │ │\n",
      "│ │                              │   │   │   top_p=1.0,                     │ │\n",
      "│ │                              │   │   │   n=1,                           │ │\n",
      "│ │                              │   │   │   frequency_penalty=0.0,         │ │\n",
      "│ │                              │   │   │   presence_penalty=0.0,          │ │\n",
      "│ │                              │   │   │   request_timeout=180.0,         │ │\n",
      "│ │                              │   │   │   api_base=None,                 │ │\n",
      "│ │                              │   │   │   api_version=None,              │ │\n",
      "│ │                              │   │   │   organization=None,             │ │\n",
      "│ │                              │   │   │   proxy=None,                    │ │\n",
      "│ │                              │   │   │   audience=None,                 │ │\n",
      "│ │                              │   │   │   deployment_name=None,          │ │\n",
      "│ │                              │   │   │   model_supports_json=None,      │ │\n",
      "│ │                              │   │   │   tokens_per_minute=0,           │ │\n",
      "│ │                              │   │   │   requests_per_minute=0,         │ │\n",
      "│ │                              │   │   │   max_retries=10,                │ │\n",
      "│ │                              │   │   │   max_retry_wait=10.0,           │ │\n",
      "│ │                              │   │   │                                  │ │\n",
      "│ │                              sleep_on_rate_limit_recommendation=True,   │ │\n",
      "│ │                              │   │   │   concurrent_requests=25,        │ │\n",
      "│ │                              │   │   │   responses=None                 │ │\n",
      "│ │                              │   │   ),                                 │ │\n",
      "│ │                              │   │                                      │ │\n",
      "│ │                              parallelization=ParallelizationParameters( │ │\n",
      "│ │                              │   │   │   stagger=0.3,                   │ │\n",
      "│ │                              │   │   │   num_threads=50                 │ │\n",
      "│ │                              │   │   ),                                 │ │\n",
      "│ │                              │   │   async_mode=<AsyncType.Threaded:    │ │\n",
      "│ │                              'threaded'>,                               │ │\n",
      "│ │                              │   │   prompt=None,                       │ │\n",
      "│ │                              │   │   max_length=500,                    │ │\n",
      "│ │                              │   │   strategy=None                      │ │\n",
      "│ │                              │   ),                                     │ │\n",
      "│ │                              │                                          │ │\n",
      "│ │                              community_reports=CommunityReportsConfig(  │ │\n",
      "│ │                              │   │   llm=LLMParameters(                 │ │\n",
      "│ │                              │   │   │                                  │ │\n",
      "│ │                              api_key='FGH7P5rBJafjdYizJNC38PRxscCX8lYD… │ │\n",
      "│ │                              │   │   │   type=\"openai_chat\",            │ │\n",
      "│ │                              │   │   │   encoding_model='cl100k_base',  │ │\n",
      "│ │                              │   │   │   model='gpt-4-turbo-preview',   │ │\n",
      "│ │                              │   │   │   max_tokens=4000,               │ │\n",
      "│ │                              │   │   │   temperature=0.0,               │ │\n",
      "│ │                              │   │   │   top_p=1.0,                     │ │\n",
      "│ │                              │   │   │   n=1,                           │ │\n",
      "│ │                              │   │   │   frequency_penalty=0.0,         │ │\n",
      "│ │                              │   │   │   presence_penalty=0.0,          │ │\n",
      "│ │                              │   │   │   request_timeout=180.0,         │ │\n",
      "│ │                              │   │   │   api_base=None,                 │ │\n",
      "│ │                              │   │   │   api_version=None,              │ │\n",
      "│ │                              │   │   │   organization=None,             │ │\n",
      "│ │                              │   │   │   proxy=None,                    │ │\n",
      "│ │                              │   │   │   audience=None,                 │ │\n",
      "│ │                              │   │   │   deployment_name=None,          │ │\n",
      "│ │                              │   │   │   model_supports_json=None,      │ │\n",
      "│ │                              │   │   │   tokens_per_minute=0,           │ │\n",
      "│ │                              │   │   │   requests_per_minute=0,         │ │\n",
      "│ │                              │   │   │   max_retries=10,                │ │\n",
      "│ │                              │   │   │   max_retry_wait=10.0,           │ │\n",
      "│ │                              │   │   │                                  │ │\n",
      "│ │                              sleep_on_rate_limit_recommendation=True,   │ │\n",
      "│ │                              │   │   │   concurrent_requests=25,        │ │\n",
      "│ │                              │   │   │   responses=None                 │ │\n",
      "│ │                              │   │   ),                                 │ │\n",
      "│ │                              │   │                                      │ │\n",
      "│ │                              parallelization=ParallelizationParameters( │ │\n",
      "│ │                              │   │   │   stagger=0.3,                   │ │\n",
      "│ │                              │   │   │   num_threads=50                 │ │\n",
      "│ │                              │   │   ),                                 │ │\n",
      "│ │                              │   │   async_mode=<AsyncType.Threaded:    │ │\n",
      "│ │                              'threaded'>,                               │ │\n",
      "│ │                              │   │   prompt=None,                       │ │\n",
      "│ │                              │   │   max_length=2000,                   │ │\n",
      "│ │                              │   │   max_input_length=8000,             │ │\n",
      "│ │                              │   │   strategy=None                      │ │\n",
      "│ │                              │   ),                                     │ │\n",
      "│ │                              │                                          │ │\n",
      "│ │                              claim_extraction=ClaimExtractionConfig(    │ │\n",
      "│ │                              │   │   llm=LLMParameters(                 │ │\n",
      "│ │                              │   │   │                                  │ │\n",
      "│ │                              api_key='FGH7P5rBJafjdYizJNC38PRxscCX8lYD… │ │\n",
      "│ │                              │   │   │   type=\"openai_chat\",            │ │\n",
      "│ │                              │   │   │   encoding_model='cl100k_base',  │ │\n",
      "│ │                              │   │   │   model='gpt-4-turbo-preview',   │ │\n",
      "│ │                              │   │   │   max_tokens=4000,               │ │\n",
      "│ │                              │   │   │   temperature=0.0,               │ │\n",
      "│ │                              │   │   │   top_p=1.0,                     │ │\n",
      "│ │                              │   │   │   n=1,                           │ │\n",
      "│ │                              │   │   │   frequency_penalty=0.0,         │ │\n",
      "│ │                              │   │   │   presence_penalty=0.0,          │ │\n",
      "│ │                              │   │   │   request_timeout=180.0,         │ │\n",
      "│ │                              │   │   │   api_base=None,                 │ │\n",
      "│ │                              │   │   │   api_version=None,              │ │\n",
      "│ │                              │   │   │   organization=None,             │ │\n",
      "│ │                              │   │   │   proxy=None,                    │ │\n",
      "│ │                              │   │   │   audience=None,                 │ │\n",
      "│ │                              │   │   │   deployment_name=None,          │ │\n",
      "│ │                              │   │   │   model_supports_json=None,      │ │\n",
      "│ │                              │   │   │   tokens_per_minute=0,           │ │\n",
      "│ │                              │   │   │   requests_per_minute=0,         │ │\n",
      "│ │                              │   │   │   max_retries=10,                │ │\n",
      "│ │                              │   │   │   max_retry_wait=10.0,           │ │\n",
      "│ │                              │   │   │                                  │ │\n",
      "│ │                              sleep_on_rate_limit_recommendation=True,   │ │\n",
      "│ │                              │   │   │   concurrent_requests=25,        │ │\n",
      "│ │                              │   │   │   responses=None                 │ │\n",
      "│ │                              │   │   ),                                 │ │\n",
      "│ │                              │   │                                      │ │\n",
      "│ │                              parallelization=ParallelizationParameters( │ │\n",
      "│ │                              │   │   │   stagger=0.3,                   │ │\n",
      "│ │                              │   │   │   num_threads=50                 │ │\n",
      "│ │                              │   │   ),                                 │ │\n",
      "│ │                              │   │   async_mode=<AsyncType.Threaded:    │ │\n",
      "│ │                              'threaded'>,                               │ │\n",
      "│ │                              │   │   enabled=False,                     │ │\n",
      "│ │                              │   │   prompt=None,                       │ │\n",
      "│ │                              │   │   description='Any claims or facts   │ │\n",
      "│ │                              that could be relevant to information      │ │\n",
      "│ │                              discovery.',                               │ │\n",
      "│ │                              │   │   max_gleanings=1,                   │ │\n",
      "│ │                              │   │   strategy=None,                     │ │\n",
      "│ │                              │   │   encoding_model='cl100k_base'       │ │\n",
      "│ │                              │   ),                                     │ │\n",
      "│ │                              │   cluster_graph=ClusterGraphConfig(      │ │\n",
      "│ │                              │   │   max_cluster_size=10,               │ │\n",
      "│ │                              │   │   use_lcc=True,                      │ │\n",
      "│ │                              │   │   seed=3735928559                    │ │\n",
      "│ │                              │   ),                                     │ │\n",
      "│ │                              │   umap=UmapConfig(enabled=False),        │ │\n",
      "│ │                              │   local_search=LocalSearchConfig(        │ │\n",
      "│ │                              │   │   prompt=None,                       │ │\n",
      "│ │                              │   │   text_unit_prop=0.5,                │ │\n",
      "│ │                              │   │   community_prop=0.15,               │ │\n",
      "│ │                              │   │   conversation_history_max_turns=5,  │ │\n",
      "│ │                              │   │   top_k_entities=10,                 │ │\n",
      "│ │                              │   │   top_k_relationships=10,            │ │\n",
      "│ │                              │   │   temperature=0.0,                   │ │\n",
      "│ │                              │   │   top_p=1.0,                         │ │\n",
      "│ │                              │   │   n=1,                               │ │\n",
      "│ │                              │   │   max_tokens=12000,                  │ │\n",
      "│ │                              │   │   llm_max_tokens=2000                │ │\n",
      "│ │                              │   ),                                     │ │\n",
      "│ │                              │   global_search=GlobalSearchConfig(      │ │\n",
      "│ │                              │   │   map_prompt=None,                   │ │\n",
      "│ │                              │   │   reduce_prompt=None,                │ │\n",
      "│ │                              │   │   knowledge_prompt=None,             │ │\n",
      "│ │                              │   │   temperature=0.0,                   │ │\n",
      "│ │                              │   │   top_p=1.0,                         │ │\n",
      "│ │                              │   │   n=1,                               │ │\n",
      "│ │                              │   │   max_tokens=12000,                  │ │\n",
      "│ │                              │   │   data_max_tokens=12000,             │ │\n",
      "│ │                              │   │   map_max_tokens=1000,               │ │\n",
      "│ │                              │   │   reduce_max_tokens=2000,            │ │\n",
      "│ │                              │   │   concurrency=32,                    │ │\n",
      "│ │                              │   │   dynamic_search_llm='gpt-4o-mini',  │ │\n",
      "│ │                              │   │   dynamic_search_threshold=1,        │ │\n",
      "│ │                              │   │   dynamic_search_keep_parent=False,  │ │\n",
      "│ │                              │   │   dynamic_search_num_repeats=1,      │ │\n",
      "│ │                              │   │   dynamic_search_use_summary=False,  │ │\n",
      "│ │                              │   │                                      │ │\n",
      "│ │                              dynamic_search_concurrent_coroutines=16,   │ │\n",
      "│ │                              │   │   dynamic_search_max_level=2         │ │\n",
      "│ │                              │   ),                                     │ │\n",
      "│ │                              │   drift_search=DRIFTSearchConfig(        │ │\n",
      "│ │                              │   │   prompt=None,                       │ │\n",
      "│ │                              │   │   temperature=0.0,                   │ │\n",
      "│ │                              │   │   top_p=1.0,                         │ │\n",
      "│ │                              │   │   n=3,                               │ │\n",
      "│ │                              │   │   max_tokens=12000,                  │ │\n",
      "│ │                              │   │   data_max_tokens=12000,             │ │\n",
      "│ │                              │   │   concurrency=32,                    │ │\n",
      "│ │                              │   │   drift_k_followups=20,              │ │\n",
      "│ │                              │   │   primer_folds=5,                    │ │\n",
      "│ │                              │   │   primer_llm_max_tokens=12000,       │ │\n",
      "│ │                              │   │   n_depth=3,                         │ │\n",
      "│ │                              │   │   local_search_text_unit_prop=0.9,   │ │\n",
      "│ │                              │   │   local_search_community_prop=0.1,   │ │\n",
      "│ │                              │   │                                      │ │\n",
      "│ │                              local_search_top_k_mapped_entities=10,     │ │\n",
      "│ │                              │   │                                      │ │\n",
      "│ │                              local_search_top_k_relationships=10,       │ │\n",
      "│ │                              │   │                                      │ │\n",
      "│ │                              local_search_max_data_tokens=12000,        │ │\n",
      "│ │                              │   │   local_search_temperature=0.0,      │ │\n",
      "│ │                              │   │   local_search_top_p=1.0,            │ │\n",
      "│ │                              │   │   local_search_n=1,                  │ │\n",
      "│ │                              │   │                                      │ │\n",
      "│ │                              local_search_llm_max_gen_tokens=2000       │ │\n",
      "│ │                              │   ),                                     │ │\n",
      "│ │                              │   basic_search=BasicSearchConfig(        │ │\n",
      "│ │                              │   │   prompt=None,                       │ │\n",
      "│ │                              │   │   text_unit_prop=0.5,                │ │\n",
      "│ │                              │   │   conversation_history_max_turns=5,  │ │\n",
      "│ │                              │   │   temperature=0.0,                   │ │\n",
      "│ │                              │   │   top_p=1.0,                         │ │\n",
      "│ │                              │   │   n=1,                               │ │\n",
      "│ │                              │   │   max_tokens=12000,                  │ │\n",
      "│ │                              │   │   llm_max_tokens=2000                │ │\n",
      "│ │                              │   ),                                     │ │\n",
      "│ │                              │   encoding_model='cl100k_base',          │ │\n",
      "│ │                              │   skip_workflows=[]                      │ │\n",
      "│ │                              )                                          │ │\n",
      "│ │ pattern_or_timestamp_value = '20250113-161436'                          │ │\n",
      "│ └─────────────────────────────────────────────────────────────────────────┘ │\n",
      "└─────────────────────────────────────────────────────────────────────────────┘\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create graph \n",
    "import subprocess \n",
    "\n",
    "commands=['graphrag','index',\"--root\",'.']\n",
    "\n",
    "try:\n",
    "    results=subprocess.run(commands,capture_output=True,text=True,check=True)\n",
    "    # print the output \n",
    "    print('Command executed successfully')\n",
    "    print('output')\n",
    "    print(results.stdout)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    # handle error \n",
    "    print('error executing the command')\n",
    "    print(e.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m command \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-m\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraphrag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--query\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwho are some famous people interacted with to elon musk, provide their names\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m ]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Run the command and capture the output\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommand executed successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\pythonProjects\\KAG_Testing\\graphragvenv\\lib\\subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[1;32md:\\pythonProjects\\KAG_Testing\\graphragvenv\\lib\\subprocess.py:1154\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1151\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1154\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\pythonProjects\\KAG_Testing\\graphragvenv\\lib\\subprocess.py:1544\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1540\u001b[0m \u001b[38;5;66;03m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;66;03m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;66;03m# calls communicate again.\u001b[39;00m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1544\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remaining_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m   1546\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, orig_timeout)\n",
      "File \u001b[1;32md:\\pythonProjects\\KAG_Testing\\graphragvenv\\lib\\threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32md:\\pythonProjects\\KAG_Testing\\graphragvenv\\lib\\threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Define the command as a list of arguments\n",
    "command = [\n",
    "    \"python\", \"-m\", \"graphrag\", \"query\",\n",
    "    \"--method\", \"global\",\n",
    "    \"--query\", \"who are some famous people interacted with to elon musk, provide their names\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Run the command and capture the output\n",
    "    result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "    print(\"Command executed successfully.\")\n",
    "    print(\"Output:\")\n",
    "    print(result.stdout)  # Print the output of the command\n",
    "except subprocess.CalledProcessError as e:\n",
    "    # Handle errors\n",
    "    print(\"Error executing the command:\")\n",
    "    print(e.stderr)  # Print the error message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
